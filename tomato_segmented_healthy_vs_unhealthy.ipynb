{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ymbTkt1vHTJT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "#from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCeLQ6_sHoF2",
    "outputId": "08b30eb6-ea44-45aa-9976-f5187268b79d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_sEI7XS9Hh2T"
   },
   "outputs": [],
   "source": [
    "#Set the image size as per the VGG16 archetecture\n",
    "IMAGE_SIZE = [256, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ip43oBQSHj9_",
    "outputId": "7a878f0e-45b0-4563-ff96-6ead40ffce9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seKyY0iwHmAS",
    "outputId": "8c43bc1d-4669-425b-c21e-1c10f1109a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDrive\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1FPNGQZEH2yd"
   },
   "outputs": [],
   "source": [
    "#Give dataset path\n",
    "train_path = 'X:\\\\Projects\\\\segmented\\\\train'\n",
    "# validation_path = 'X:\\\\Projects\\\\tomato\\\\val'\n",
    "test_path = 'X:\\\\Projects\\\\segmented\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w0VLin0HH9UM"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "def count(dir, counter=0):\n",
    "    \"returns number of files in dir and subdirs\"\n",
    "    for pack in os.walk(dir):\n",
    "        for f in pack[2]:\n",
    "            counter += 1\n",
    "    return dir + \" : \" + str(counter) + \"files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1P1QjYhhaqE",
    "outputId": "26ed6971-cdd7-4152-b031-0eedb82c5a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images for training : X:\\Projects\\segmented\\train : 7460files\n",
      "total images for validation : X:\\Projects\\segmented\\test : 1865files\n"
     ]
    }
   ],
   "source": [
    "print('total images for training :', count(train_path))\n",
    "# print('total images for validation :', count(validation_path))\n",
    "print('total images for validation :', count(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2UOsr8CIh8W",
    "outputId": "5b213653-2c6a-4f0f-eb29-0a48875ed5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "folders = glob('X:\\\\Projects\\\\segmented\\\\train\\\\*')\n",
    "print(len(folders))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kWKNSZfiKAhS"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_generator = ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.1) # VGG16 preprocessing\n",
    "\n",
    "# validation_generator = ImageDataGenerator(preprocessing_function=preprocess_input) \n",
    "\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvg_tLEaJw06",
    "outputId": "1b40c140-ed8e-4dec-dc01-744bce2bc4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bacterialspot', 'earlyblight', 'healthy', 'lateblight', 'leafmold', 'mosaicvirus', 'septorialeafspot', 'spidermites', 'targetspot', 'yellowleafcurlvirus']\n",
      "Found 6715 images belonging to 10 classes.\n",
      "Found 745 images belonging to 10 classes.\n",
      "Found 1865 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "class_subset = sorted(os.listdir('X:\\\\Projects\\\\segmented\\\\train'))\n",
    "print(class_subset)\n",
    "traingen = train_generator.flow_from_directory(train_path,\n",
    "                                               target_size=(256, 256),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=class_subset,\n",
    "                                               subset='training',\n",
    "                                               batch_size=BATCH_SIZE, \n",
    "                                               shuffle=True,\n",
    "                                               seed=5)\n",
    "\n",
    "validgen = train_generator.flow_from_directory(train_path,\n",
    "                                               target_size=(256, 256),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=class_subset,\n",
    "                                               subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=4)\n",
    "\n",
    "testgen = test_generator.flow_from_directory(test_path,\n",
    "                                             target_size=(256, 256),\n",
    "                                             class_mode=None,\n",
    "                                             classes=class_subset,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7bqEPLfQ68Q"
   },
   "source": [
    "# **VGG16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NfwZt7lQtdt",
    "outputId": "d3e3054a-61dd-405e-ceae-c4858964e1c2"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model1 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "X5XDzROhQth6"
   },
   "outputs": [],
   "source": [
    "for layer in model1.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpfFgaqnDz1U",
    "outputId": "4d2bd4b8-fa3e-4830-b31c-0d8c86484fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2S96C1OcQtmw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "batnorm = layers.BatchNormalization()\n",
    "dropout = layers.Dropout(0.20)\n",
    "prediction_layer = layers.Dense(10, activation='sigmoid')\n",
    "\n",
    "\n",
    "vgg16 = models.Sequential([\n",
    "    model1,\n",
    "    flatten_layer,\n",
    "    batnorm,\n",
    "    dropout,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQh6SGWSQtpI",
    "outputId": "37d164ac-7a4c-4a88-9d5d-f00628c01e0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32768)             131072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                327690    \n",
      "=================================================================\n",
      "Total params: 15,173,450\n",
      "Trainable params: 393,226\n",
      "Non-trainable params: 14,780,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fW1pFlgtQtwD",
    "outputId": "902d0ae3-21ff-43d0-b89b-15d2881cb924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "209/209 [==============================] - 79s 376ms/step - loss: 0.8377 - accuracy: 0.7510 - val_loss: 0.6753 - val_accuracy: 0.8370\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83696, saving model to X:\\Projects\\segmented\\vgg16.h5\n",
      "Epoch 2/50\n",
      "209/209 [==============================] - 80s 381ms/step - loss: 0.1187 - accuracy: 0.9602 - val_loss: 0.6599 - val_accuracy: 0.8655\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.83696 to 0.86549, saving model to X:\\Projects\\segmented\\vgg16.h5\n",
      "Epoch 3/50\n",
      "209/209 [==============================] - 80s 383ms/step - loss: 0.0518 - accuracy: 0.9825 - val_loss: 0.8867 - val_accuracy: 0.8546\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.86549\n",
      "Epoch 4/50\n",
      "209/209 [==============================] - 80s 384ms/step - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.7835 - val_accuracy: 0.8668\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.86549 to 0.86685, saving model to X:\\Projects\\segmented\\vgg16.h5\n",
      "Epoch 5/50\n",
      "209/209 [==============================] - 81s 387ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 1.0033 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.86685\n",
      "Epoch 6/50\n",
      "209/209 [==============================] - 80s 382ms/step - loss: 0.0364 - accuracy: 0.9880 - val_loss: 1.1140 - val_accuracy: 0.8519\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.86685\n",
      "Epoch 7/50\n",
      "209/209 [==============================] - 78s 375ms/step - loss: 0.0383 - accuracy: 0.9852 - val_loss: 1.1285 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.86685\n",
      "Epoch 8/50\n",
      "209/209 [==============================] - 78s 373ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 1.1826 - val_accuracy: 0.8546\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.86685\n",
      "Epoch 9/50\n",
      "209/209 [==============================] - 78s 374ms/step - loss: 0.0380 - accuracy: 0.9885 - val_loss: 1.3274 - val_accuracy: 0.8451\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.86685\n",
      "Epoch 10/50\n",
      "209/209 [==============================] - 79s 377ms/step - loss: 0.0443 - accuracy: 0.9856 - val_loss: 1.3792 - val_accuracy: 0.8315\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.86685\n",
      "Epoch 11/50\n",
      "209/209 [==============================] - 79s 378ms/step - loss: 0.0647 - accuracy: 0.9801 - val_loss: 1.5618 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.86685\n",
      "Epoch 12/50\n",
      "209/209 [==============================] - 79s 376ms/step - loss: 0.0613 - accuracy: 0.9825 - val_loss: 1.3433 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.86685\n",
      "Epoch 13/50\n",
      "209/209 [==============================] - 78s 375ms/step - loss: 0.0814 - accuracy: 0.9791 - val_loss: 1.8362 - val_accuracy: 0.8043\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.86685\n",
      "Epoch 14/50\n",
      "209/209 [==============================] - 78s 373ms/step - loss: 0.0626 - accuracy: 0.9840 - val_loss: 1.8877 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.86685\n",
      "Epoch 15/50\n",
      "209/209 [==============================] - 78s 375ms/step - loss: 0.0752 - accuracy: 0.9799 - val_loss: 1.6437 - val_accuracy: 0.8465\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.86685\n",
      "Epoch 16/50\n",
      "209/209 [==============================] - 78s 375ms/step - loss: 0.0578 - accuracy: 0.9859 - val_loss: 1.7598 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.86685\n",
      "Epoch 17/50\n",
      "209/209 [==============================] - 78s 373ms/step - loss: 0.0533 - accuracy: 0.9850 - val_loss: 1.7284 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.86685\n",
      "Epoch 18/50\n",
      "209/209 [==============================] - 78s 373ms/step - loss: 0.0583 - accuracy: 0.9864 - val_loss: 1.8867 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.86685\n",
      "Epoch 19/50\n",
      "209/209 [==============================] - 78s 372ms/step - loss: 0.0618 - accuracy: 0.9879 - val_loss: 1.9548 - val_accuracy: 0.8424\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.86685\n",
      "Epoch 20/50\n",
      "209/209 [==============================] - 78s 374ms/step - loss: 0.0538 - accuracy: 0.9856 - val_loss: 2.0998 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.86685\n",
      "Epoch 21/50\n",
      "209/209 [==============================] - 78s 373ms/step - loss: 0.0367 - accuracy: 0.9909 - val_loss: 2.0964 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86685\n",
      "Epoch 22/50\n",
      "209/209 [==============================] - 78s 371ms/step - loss: 0.0493 - accuracy: 0.9886 - val_loss: 2.1330 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.86685\n",
      "Epoch 23/50\n",
      "209/209 [==============================] - 78s 373ms/step - loss: 0.0562 - accuracy: 0.9883 - val_loss: 2.3452 - val_accuracy: 0.8247\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86685\n",
      "Epoch 24/50\n",
      "209/209 [==============================] - 77s 370ms/step - loss: 0.0446 - accuracy: 0.9888 - val_loss: 2.2770 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86685\n",
      "Epoch 25/50\n",
      "209/209 [==============================] - 77s 370ms/step - loss: 0.0370 - accuracy: 0.9907 - val_loss: 2.2204 - val_accuracy: 0.8315\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86685\n",
      "Epoch 26/50\n",
      "209/209 [==============================] - 77s 370ms/step - loss: 0.0549 - accuracy: 0.9894 - val_loss: 2.3043 - val_accuracy: 0.8315\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86685\n",
      "Epoch 27/50\n",
      "209/209 [==============================] - 77s 368ms/step - loss: 0.0382 - accuracy: 0.9912 - val_loss: 2.2444 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86685\n",
      "Epoch 28/50\n",
      "209/209 [==============================] - 77s 370ms/step - loss: 0.0417 - accuracy: 0.9909 - val_loss: 2.6114 - val_accuracy: 0.8247\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86685\n",
      "Epoch 29/50\n",
      "209/209 [==============================] - 77s 368ms/step - loss: 0.0515 - accuracy: 0.9904 - val_loss: 2.7831 - val_accuracy: 0.8424\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86685\n",
      "Epoch 30/50\n",
      "209/209 [==============================] - 77s 368ms/step - loss: 0.0445 - accuracy: 0.9924 - val_loss: 2.3324 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86685\n",
      "Epoch 31/50\n",
      "209/209 [==============================] - 77s 368ms/step - loss: 0.0509 - accuracy: 0.9915 - val_loss: 2.5566 - val_accuracy: 0.8397\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86685\n",
      "Epoch 32/50\n",
      "209/209 [==============================] - 77s 369ms/step - loss: 0.0248 - accuracy: 0.9940 - val_loss: 2.6447 - val_accuracy: 0.8370\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86685\n",
      "Epoch 33/50\n",
      "209/209 [==============================] - 77s 371ms/step - loss: 0.0366 - accuracy: 0.9921 - val_loss: 2.5534 - val_accuracy: 0.8397\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86685\n",
      "Epoch 34/50\n",
      "209/209 [==============================] - 78s 374ms/step - loss: 0.0522 - accuracy: 0.9910 - val_loss: 2.2093 - val_accuracy: 0.8533\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86685\n",
      "Epoch 35/50\n",
      "209/209 [==============================] - 80s 383ms/step - loss: 0.0373 - accuracy: 0.9925 - val_loss: 2.4950 - val_accuracy: 0.8410\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86685\n",
      "Epoch 36/50\n",
      "209/209 [==============================] - 80s 380ms/step - loss: 0.0364 - accuracy: 0.9928 - val_loss: 2.4218 - val_accuracy: 0.8410\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86685\n",
      "Epoch 37/50\n",
      "209/209 [==============================] - 80s 381ms/step - loss: 0.0318 - accuracy: 0.9931 - val_loss: 2.5800 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86685\n",
      "Epoch 38/50\n",
      "209/209 [==============================] - 80s 382ms/step - loss: 0.0461 - accuracy: 0.9921 - val_loss: 2.3848 - val_accuracy: 0.8505\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86685\n",
      "Epoch 39/50\n",
      "209/209 [==============================] - 80s 382ms/step - loss: 0.0469 - accuracy: 0.9921 - val_loss: 2.4641 - val_accuracy: 0.8370\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86685\n",
      "Epoch 40/50\n",
      "209/209 [==============================] - 79s 380ms/step - loss: 0.0479 - accuracy: 0.9916 - val_loss: 2.6897 - val_accuracy: 0.8424\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86685\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 80s 382ms/step - loss: 0.0393 - accuracy: 0.9934 - val_loss: 2.5948 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86685\n",
      "Epoch 42/50\n",
      "209/209 [==============================] - 80s 382ms/step - loss: 0.0272 - accuracy: 0.9945 - val_loss: 2.4717 - val_accuracy: 0.8519\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86685\n",
      "Epoch 43/50\n",
      "209/209 [==============================] - 80s 381ms/step - loss: 0.0233 - accuracy: 0.9945 - val_loss: 2.4661 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86685\n",
      "Epoch 44/50\n",
      "209/209 [==============================] - 80s 382ms/step - loss: 0.0502 - accuracy: 0.9915 - val_loss: 2.7443 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86685\n",
      "Epoch 45/50\n",
      "209/209 [==============================] - 78s 375ms/step - loss: 0.0388 - accuracy: 0.9939 - val_loss: 2.3924 - val_accuracy: 0.8424\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86685\n",
      "Epoch 46/50\n",
      "209/209 [==============================] - 79s 378ms/step - loss: 0.0325 - accuracy: 0.9943 - val_loss: 2.3461 - val_accuracy: 0.8546\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86685\n",
      "Epoch 47/50\n",
      "209/209 [==============================] - 80s 381ms/step - loss: 0.0479 - accuracy: 0.9919 - val_loss: 2.7512 - val_accuracy: 0.8505\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86685\n",
      "Epoch 48/50\n",
      "209/209 [==============================] - 80s 381ms/step - loss: 0.0228 - accuracy: 0.9957 - val_loss: 2.4531 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86685\n",
      "Epoch 49/50\n",
      "209/209 [==============================] - 80s 384ms/step - loss: 0.0408 - accuracy: 0.9946 - val_loss: 2.4454 - val_accuracy: 0.8519\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86685\n",
      "Epoch 50/50\n",
      "209/209 [==============================] - 79s 376ms/step - loss: 0.0399 - accuracy: 0.9942 - val_loss: 2.3347 - val_accuracy: 0.8519\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86685\n"
     ]
    }
   ],
   "source": [
    "optimizer=Adam(learning_rate=0.001)\n",
    "vgg16.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "optim_1 = Adam(learning_rate=0.001)\n",
    "#n_classes=3\n",
    "\n",
    "n_steps = traingen.samples // BATCH_SIZE\n",
    "n_val_steps = validgen.samples // BATCH_SIZE\n",
    "n_epochs = 50\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='X:\\\\Projects\\\\segmented\\\\vgg16.h5',\n",
    "                                  save_best_only=True,\n",
    "                                  monitor='val_accuracy',\n",
    "                                  mode='max',\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "\n",
    "vgg_history = vgg16.fit(traingen,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=n_epochs,\n",
    "                            validation_data=validgen,\n",
    "                            steps_per_epoch=n_steps,\n",
    "                            validation_steps=n_val_steps,\n",
    "                            callbacks=[tl_checkpoint_1], \n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "USB2Vx_RQt0P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Generate predictions\n",
    "vgg16.load_weights('X:\\\\Projects\\\\segmented\\\\vgg16.h5') # initialize the best trained weights\n",
    "\n",
    "true_classes = testgen.classes\n",
    "class_indices = traingen.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "vgg_preds = vgg16.predict(testgen)\n",
    "vgg_pred_classes = np.argmax(vgg_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdK5KqiWbwiq",
    "outputId": "55af6a63-b3de-4a10-d836-6e24df793735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 Model Accuracy without Fine-Tuning: 83.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vgg_acc = accuracy_score(true_classes, vgg_pred_classes)\n",
    "print(\"VGG16 Model Accuracy without Fine-Tuning: {:.2f}%\".format(vgg_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRj2ZJ_nb5WY",
    "outputId": "0ee26ff2-4644-457c-cdc1-dd6c4c9c0ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       200\n",
      "           1       0.67      0.69      0.68       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "           3       0.87      0.81      0.84       200\n",
      "           4       0.86      0.86      0.86       190\n",
      "           5       0.88      0.91      0.89        75\n",
      "           6       0.83      0.75      0.79       200\n",
      "           7       0.90      0.93      0.91       200\n",
      "           8       0.74      0.79      0.77       200\n",
      "           9       0.97      0.93      0.95       200\n",
      "\n",
      "    accuracy                           0.84      1865\n",
      "   macro avg       0.84      0.84      0.84      1865\n",
      "weighted avg       0.84      0.84      0.84      1865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(true_classes,vgg_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukUvLfMsb5Y5",
    "outputId": "41aec502-0495-4565-be27-2d2600e4e36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176   5   0   1   4   2   7   0   4   1]\n",
      " [ 11 137   5  15   6   2  11   3   9   1]\n",
      " [  1   3 174   0   1   1   0   3  17   0]\n",
      " [  4  16   3 163   8   0   3   0   3   0]\n",
      " [  0   7   5   2 164   1   0   3   5   3]\n",
      " [  0   1   0   1   2  68   1   1   0   1]\n",
      " [ 10  24   2   4   2   2 150   0   6   0]\n",
      " [  0   3   0   0   1   0   1 185  10   0]\n",
      " [ 10   5  13   1   2   0   6   5 158   0]\n",
      " [  1   3   0   1   0   1   1   6   1 186]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(true_classes,vgg_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLHlCxgZkx7f"
   },
   "source": [
    "# **ResNet152**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdvBEolGWaBV",
    "outputId": "1b924b1e-2d91-4d84-9e45-7397bd2a8404"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import keras\n",
    "model6 = tf.keras.applications.ResNet152(include_top=False, weights='imagenet', input_shape=(256,256,3))\n",
    "for layer in model6.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3zw_HYpk7GT",
    "outputId": "0c7be66e-ffcc-43aa-f9f6-ad70ec2e0973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet152\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 32, 32, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_relu (Activation (None, 32, 32, 128)  0           conv3_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_add (Add)          (None, 32, 32, 512)  0           conv3_block4_out[0][0]           \n",
      "                                                                 conv3_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_out (Activation)   (None, 32, 32, 512)  0           conv3_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 32, 32, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_relu (Activation (None, 32, 32, 128)  0           conv3_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_add (Add)          (None, 32, 32, 512)  0           conv3_block5_out[0][0]           \n",
      "                                                                 conv3_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_out (Activation)   (None, 32, 32, 512)  0           conv3_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 32, 32, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_relu (Activation (None, 32, 32, 128)  0           conv3_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_add (Add)          (None, 32, 32, 512)  0           conv3_block6_out[0][0]           \n",
      "                                                                 conv3_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_out (Activation)   (None, 32, 32, 512)  0           conv3_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 32, 32, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_relu (Activation (None, 32, 32, 128)  0           conv3_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_add (Add)          (None, 32, 32, 512)  0           conv3_block7_out[0][0]           \n",
      "                                                                 conv3_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_out (Activation)   (None, 32, 32, 512)  0           conv3_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 16, 16, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 16, 16, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 16, 16, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 16, 16, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 16, 16, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 16, 16, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 16, 16, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 16, 16, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 16, 16, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 16, 16, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 16, 16, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 16, 16, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 16, 16, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 16, 16, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 16, 16, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 16, 16, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 16, 16, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 16, 16, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 16, 16, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 16, 16, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 16, 16, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 16, 16, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 16, 16, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 16, 16, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 16, 16, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 16, 16, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 16, 16, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 16, 16, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 16, 16, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 16, 16, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 16, 16, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 16, 16, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 16, 16, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 16, 16, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 16, 16, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 16, 16, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 16, 16, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 16, 16, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 16, 16, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 16, 16, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block24_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block24_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_add (Add)         (None, 16, 16, 1024) 0           conv4_block23_out[0][0]          \n",
      "                                                                 conv4_block24_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_out (Activation)  (None, 16, 16, 1024) 0           conv4_block24_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block24_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block25_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block25_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_add (Add)         (None, 16, 16, 1024) 0           conv4_block24_out[0][0]          \n",
      "                                                                 conv4_block25_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_out (Activation)  (None, 16, 16, 1024) 0           conv4_block25_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block25_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block26_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block26_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_add (Add)         (None, 16, 16, 1024) 0           conv4_block25_out[0][0]          \n",
      "                                                                 conv4_block26_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_out (Activation)  (None, 16, 16, 1024) 0           conv4_block26_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block26_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block27_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block27_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_add (Add)         (None, 16, 16, 1024) 0           conv4_block26_out[0][0]          \n",
      "                                                                 conv4_block27_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_out (Activation)  (None, 16, 16, 1024) 0           conv4_block27_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block27_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block28_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block28_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_add (Add)         (None, 16, 16, 1024) 0           conv4_block27_out[0][0]          \n",
      "                                                                 conv4_block28_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_out (Activation)  (None, 16, 16, 1024) 0           conv4_block28_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block28_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block29_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block29_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_add (Add)         (None, 16, 16, 1024) 0           conv4_block28_out[0][0]          \n",
      "                                                                 conv4_block29_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_out (Activation)  (None, 16, 16, 1024) 0           conv4_block29_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block29_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block30_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block30_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_add (Add)         (None, 16, 16, 1024) 0           conv4_block29_out[0][0]          \n",
      "                                                                 conv4_block30_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_out (Activation)  (None, 16, 16, 1024) 0           conv4_block30_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block30_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block31_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block31_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_add (Add)         (None, 16, 16, 1024) 0           conv4_block30_out[0][0]          \n",
      "                                                                 conv4_block31_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_out (Activation)  (None, 16, 16, 1024) 0           conv4_block31_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block31_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block32_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block32_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_add (Add)         (None, 16, 16, 1024) 0           conv4_block31_out[0][0]          \n",
      "                                                                 conv4_block32_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_out (Activation)  (None, 16, 16, 1024) 0           conv4_block32_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block32_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block33_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block33_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_add (Add)         (None, 16, 16, 1024) 0           conv4_block32_out[0][0]          \n",
      "                                                                 conv4_block33_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_out (Activation)  (None, 16, 16, 1024) 0           conv4_block33_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block33_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block34_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block34_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_add (Add)         (None, 16, 16, 1024) 0           conv4_block33_out[0][0]          \n",
      "                                                                 conv4_block34_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_out (Activation)  (None, 16, 16, 1024) 0           conv4_block34_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block34_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block35_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block35_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_add (Add)         (None, 16, 16, 1024) 0           conv4_block34_out[0][0]          \n",
      "                                                                 conv4_block35_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_out (Activation)  (None, 16, 16, 1024) 0           conv4_block35_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block35_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block36_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block36_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block36_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_add (Add)         (None, 16, 16, 1024) 0           conv4_block35_out[0][0]          \n",
      "                                                                 conv4_block36_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_out (Activation)  (None, 16, 16, 1024) 0           conv4_block36_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block36_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block36_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 58,370,944\n",
      "Trainable params: 0\n",
      "Non-trainable params: 58,370,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gE7kYfFkk_pA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "batnorm = layers.BatchNormalization()\n",
    "dropout = layers.Dropout(0.20)\n",
    "prediction_layer = layers.Dense(10, activation='sigmoid')\n",
    "\n",
    "resnet152 = models.Sequential([\n",
    "    model6,\n",
    "    flatten_layer,\n",
    "    batnorm,\n",
    "    dropout,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV4YQqrzlEit",
    "outputId": "79542b43-8044-423a-8439-fd36149c6f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet152 (Functional)       (None, 8, 8, 2048)        58370944  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 131072)            524288    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1310730   \n",
      "=================================================================\n",
      "Total params: 60,205,962\n",
      "Trainable params: 1,572,874\n",
      "Non-trainable params: 58,633,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet152.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlAtN3dwlGVD",
    "outputId": "530c72f4-28c6-4eec-9764-75014f6027a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "209/209 [==============================] - 130s 570ms/step - loss: 1.8205 - accuracy: 0.7815 - val_loss: 1.2817 - val_accuracy: 0.8668\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.86685, saving model to X:\\Projects\\segmented\\resnet152.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhala\\anaconda3\\envs\\NNDL\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "209/209 [==============================] - 121s 577ms/step - loss: 0.5258 - accuracy: 0.9439 - val_loss: 1.2145 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.86685 to 0.90082, saving model to X:\\Projects\\segmented\\resnet152.h5\n",
      "Epoch 3/50\n",
      "209/209 [==============================] - 120s 574ms/step - loss: 0.2215 - accuracy: 0.9695 - val_loss: 2.2042 - val_accuracy: 0.8954\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.90082\n",
      "Epoch 4/50\n",
      "209/209 [==============================] - 122s 585ms/step - loss: 0.2315 - accuracy: 0.9722 - val_loss: 2.5798 - val_accuracy: 0.8886\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.90082\n",
      "Epoch 5/50\n",
      "209/209 [==============================] - 123s 589ms/step - loss: 0.1687 - accuracy: 0.9789 - val_loss: 1.9965 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.90082 to 0.90625, saving model to X:\\Projects\\segmented\\resnet152.h5\n",
      "Epoch 6/50\n",
      "209/209 [==============================] - 122s 584ms/step - loss: 0.1577 - accuracy: 0.9808 - val_loss: 2.7192 - val_accuracy: 0.8764\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.90625\n",
      "Epoch 7/50\n",
      "209/209 [==============================] - 123s 587ms/step - loss: 0.1861 - accuracy: 0.9813 - val_loss: 2.3551 - val_accuracy: 0.8818\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.90625\n",
      "Epoch 8/50\n",
      "209/209 [==============================] - 122s 581ms/step - loss: 0.2126 - accuracy: 0.9810 - val_loss: 2.8339 - val_accuracy: 0.8818\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.90625\n",
      "Epoch 9/50\n",
      "209/209 [==============================] - 121s 578ms/step - loss: 0.1581 - accuracy: 0.9859 - val_loss: 2.8835 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.90625\n",
      "Epoch 10/50\n",
      "209/209 [==============================] - 121s 577ms/step - loss: 0.1385 - accuracy: 0.9868 - val_loss: 2.4212 - val_accuracy: 0.8981\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.90625\n",
      "Epoch 11/50\n",
      "209/209 [==============================] - 121s 577ms/step - loss: 0.1695 - accuracy: 0.9826 - val_loss: 2.8466 - val_accuracy: 0.8845\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.90625\n",
      "Epoch 12/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.2137 - accuracy: 0.9837 - val_loss: 3.0498 - val_accuracy: 0.8954\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.90625\n",
      "Epoch 13/50\n",
      "209/209 [==============================] - 121s 581ms/step - loss: 0.1335 - accuracy: 0.9891 - val_loss: 3.3422 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.90625\n",
      "Epoch 14/50\n",
      "209/209 [==============================] - 122s 584ms/step - loss: 0.1864 - accuracy: 0.9849 - val_loss: 3.4771 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.90625\n",
      "Epoch 15/50\n",
      "209/209 [==============================] - 121s 579ms/step - loss: 0.2153 - accuracy: 0.9850 - val_loss: 4.1057 - val_accuracy: 0.8954\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.90625\n",
      "Epoch 16/50\n",
      "209/209 [==============================] - 121s 579ms/step - loss: 0.1601 - accuracy: 0.9889 - val_loss: 3.4868 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.90625 to 0.90761, saving model to X:\\Projects\\segmented\\resnet152.h5\n",
      "Epoch 17/50\n",
      "209/209 [==============================] - 119s 569ms/step - loss: 0.1692 - accuracy: 0.9897 - val_loss: 4.3209 - val_accuracy: 0.8954\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.90761\n",
      "Epoch 18/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.1522 - accuracy: 0.9891 - val_loss: 4.7058 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.90761\n",
      "Epoch 19/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.1451 - accuracy: 0.9901 - val_loss: 4.3093 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.90761\n",
      "Epoch 20/50\n",
      "209/209 [==============================] - 121s 577ms/step - loss: 0.1841 - accuracy: 0.9903 - val_loss: 4.0834 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.90761 to 0.91033, saving model to X:\\Projects\\segmented\\resnet152.h5\n",
      "Epoch 21/50\n",
      "209/209 [==============================] - 118s 565ms/step - loss: 0.1346 - accuracy: 0.9910 - val_loss: 4.0515 - val_accuracy: 0.9049\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.91033\n",
      "Epoch 22/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.1930 - accuracy: 0.9897 - val_loss: 4.5599 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.91033\n",
      "Epoch 23/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.1334 - accuracy: 0.9924 - val_loss: 4.4114 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.91033\n",
      "Epoch 24/50\n",
      "209/209 [==============================] - 121s 577ms/step - loss: 0.1224 - accuracy: 0.9922 - val_loss: 4.8719 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.91033\n",
      "Epoch 25/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.0908 - accuracy: 0.9934 - val_loss: 5.5930 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.91033\n",
      "Epoch 26/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.0691 - accuracy: 0.9946 - val_loss: 4.6432 - val_accuracy: 0.9022\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.91033\n",
      "Epoch 27/50\n",
      "209/209 [==============================] - 120s 575ms/step - loss: 0.1316 - accuracy: 0.9934 - val_loss: 4.3745 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.91033\n",
      "Epoch 28/50\n",
      "209/209 [==============================] - 120s 574ms/step - loss: 0.0845 - accuracy: 0.9951 - val_loss: 4.9211 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.91033\n",
      "Epoch 29/50\n",
      "209/209 [==============================] - 120s 575ms/step - loss: 0.0742 - accuracy: 0.9952 - val_loss: 5.9753 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.91033\n",
      "Epoch 30/50\n",
      "209/209 [==============================] - 120s 574ms/step - loss: 0.1106 - accuracy: 0.9937 - val_loss: 5.9858 - val_accuracy: 0.8913\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.91033\n",
      "Epoch 31/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.1081 - accuracy: 0.9919 - val_loss: 6.3039 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.91033\n",
      "Epoch 32/50\n",
      "209/209 [==============================] - 120s 575ms/step - loss: 0.1432 - accuracy: 0.9921 - val_loss: 5.9596 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.91033\n",
      "Epoch 33/50\n",
      "209/209 [==============================] - 120s 575ms/step - loss: 0.0830 - accuracy: 0.9954 - val_loss: 6.4795 - val_accuracy: 0.8954\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.91033\n",
      "Epoch 34/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.0901 - accuracy: 0.9948 - val_loss: 5.8122 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.91033 to 0.91304, saving model to X:\\Projects\\segmented\\resnet152.h5\n",
      "Epoch 35/50\n",
      "209/209 [==============================] - 119s 568ms/step - loss: 0.1280 - accuracy: 0.9942 - val_loss: 5.9950 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.91304\n",
      "Epoch 36/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.1073 - accuracy: 0.9939 - val_loss: 6.4211 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.91304\n",
      "Epoch 37/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.1462 - accuracy: 0.9934 - val_loss: 6.0448 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.91304\n",
      "Epoch 38/50\n",
      "209/209 [==============================] - 121s 577ms/step - loss: 0.0938 - accuracy: 0.9951 - val_loss: 5.1556 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.91304\n",
      "Epoch 39/50\n",
      "209/209 [==============================] - 120s 575ms/step - loss: 0.1187 - accuracy: 0.9948 - val_loss: 6.5501 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.91304\n",
      "Epoch 40/50\n",
      "209/209 [==============================] - 120s 575ms/step - loss: 0.1212 - accuracy: 0.9943 - val_loss: 7.8749 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.91304\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 120s 575ms/step - loss: 0.1244 - accuracy: 0.9933 - val_loss: 7.0936 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.91304\n",
      "Epoch 42/50\n",
      "209/209 [==============================] - 120s 576ms/step - loss: 0.1777 - accuracy: 0.9928 - val_loss: 5.9002 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.91304\n",
      "Epoch 43/50\n",
      "209/209 [==============================] - 121s 579ms/step - loss: 0.1469 - accuracy: 0.9940 - val_loss: 5.4605 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.91304\n",
      "Epoch 44/50\n",
      "209/209 [==============================] - 123s 588ms/step - loss: 0.1029 - accuracy: 0.9948 - val_loss: 6.6051 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.91304\n",
      "Epoch 45/50\n",
      "209/209 [==============================] - 124s 593ms/step - loss: 0.1275 - accuracy: 0.9942 - val_loss: 6.4566 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.91304\n",
      "Epoch 46/50\n",
      "209/209 [==============================] - 125s 600ms/step - loss: 0.1013 - accuracy: 0.9967 - val_loss: 7.5873 - val_accuracy: 0.8981\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.91304\n",
      "Epoch 47/50\n",
      "209/209 [==============================] - 125s 598ms/step - loss: 0.0957 - accuracy: 0.9972 - val_loss: 8.3419 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.91304\n",
      "Epoch 48/50\n",
      "209/209 [==============================] - 125s 598ms/step - loss: 0.1109 - accuracy: 0.9952 - val_loss: 8.1218 - val_accuracy: 0.8845\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.91304\n",
      "Epoch 49/50\n",
      "209/209 [==============================] - 123s 590ms/step - loss: 0.0948 - accuracy: 0.9957 - val_loss: 8.9366 - val_accuracy: 0.8927\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.91304\n",
      "Epoch 50/50\n",
      "209/209 [==============================] - 125s 599ms/step - loss: 0.1185 - accuracy: 0.9952 - val_loss: 8.3171 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.91304\n"
     ]
    }
   ],
   "source": [
    "optimizer=Adam(learning_rate=0.001)\n",
    "resnet152.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "optim_1 = Adam(learning_rate=0.001)\n",
    "#n_classes=3\n",
    "\n",
    "n_steps = traingen.samples // BATCH_SIZE\n",
    "n_val_steps = validgen.samples // BATCH_SIZE\n",
    "n_epochs = 50\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='X:\\\\Projects\\\\segmented\\\\resnet152.h5',\n",
    "                                  save_best_only=True,\n",
    "                                  monitor='val_accuracy',\n",
    "                                  mode='max',\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "\n",
    "vgg_history = resnet152.fit(traingen,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=n_epochs,\n",
    "                            validation_data=validgen,\n",
    "                            steps_per_epoch=n_steps,\n",
    "                            validation_steps=n_val_steps,\n",
    "                            callbacks=[tl_checkpoint_1], \n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "1285-HBYVspX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Generate predictions\n",
    "resnet152= tf.keras.models.load_model('X:\\\\Projects\\\\segmented\\\\resnet152.h5') # initialize the best trained weights\n",
    "\n",
    "true_classes = testgen.classes\n",
    "class_indices = traingen.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "resnet152_preds = resnet152.predict(testgen)\n",
    "resnet152_pred_classes = np.argmax(resnet152_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIVwl1tDVvei",
    "outputId": "e7d0ac4f-bebe-43fb-a370-c29327cec209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet152 Model Accuracy without Fine-Tuning: 36.35%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "resnet152_acc = accuracy_score(true_classes, resnet152_pred_classes)\n",
    "print(\"ResNet152 Model Accuracy without Fine-Tuning: {:.2f}%\".format(resnet152_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JU3cJPCVyoJ",
    "outputId": "15a28db3-2834-4d0f-dd78-bafc6e6d7e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.99      0.45       200\n",
      "           1       0.30      0.52      0.38       200\n",
      "           2       0.47      0.66      0.55       200\n",
      "           3       0.48      0.35      0.41       200\n",
      "           4       0.39      0.35      0.37       190\n",
      "           5       0.34      0.28      0.31        75\n",
      "           6       0.14      0.05      0.07       200\n",
      "           7       0.69      0.29      0.41       200\n",
      "           8       0.41      0.04      0.06       200\n",
      "           9       1.00      0.04      0.09       200\n",
      "\n",
      "    accuracy                           0.36      1865\n",
      "   macro avg       0.45      0.36      0.31      1865\n",
      "weighted avg       0.46      0.36      0.31      1865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(true_classes,resnet152_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQu2EZEDlbVW",
    "outputId": "4456f124-7d56-46ea-afa5-36101d4871e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[199,   0,   0,   1,   0,   0,   0,   0,   0,   0],\n",
       "       [ 94, 104,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 47,  21, 132,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 37,  72,  20,  71,   0,   0,   0,   0,   0,   0],\n",
       "       [ 44,  24,  17,  38,  66,   0,   0,   1,   0,   0],\n",
       "       [  5,  25,   2,   3,  19,  21,   0,   0,   0,   0],\n",
       "       [113,  43,   8,   9,   9,   8,  10,   0,   0,   0],\n",
       "       [ 19,  14,  42,   4,  29,   9,  24,  59,   0,   0],\n",
       "       [ 89,  30,  36,   8,   3,   2,  14,  11,   7,   0],\n",
       "       [ 34,  13,  20,  13,  44,  21,  21,  15,  10,   9]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true_classes,resnet152_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BCD_smallData_part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
