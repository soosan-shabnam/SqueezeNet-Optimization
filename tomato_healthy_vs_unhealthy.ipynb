{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ymbTkt1vHTJT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "#from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCeLQ6_sHoF2",
    "outputId": "08b30eb6-ea44-45aa-9976-f5187268b79d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_sEI7XS9Hh2T"
   },
   "outputs": [],
   "source": [
    "#Set the image size as per the VGG16 archetecture\n",
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ip43oBQSHj9_",
    "outputId": "7a878f0e-45b0-4563-ff96-6ead40ffce9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seKyY0iwHmAS",
    "outputId": "8c43bc1d-4669-425b-c21e-1c10f1109a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDrive\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1FPNGQZEH2yd"
   },
   "outputs": [],
   "source": [
    "#Give dataset path\n",
    "train_path = 'X:\\\\Projects\\\\tomato\\\\train'\n",
    "validation_path = 'X:\\\\Projects\\\\tomato\\\\val'\n",
    "test_path = 'X:\\\\Projects\\\\tomato\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "w0VLin0HH9UM"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "def count(dir, counter=0):\n",
    "    \"returns number of files in dir and subdirs\"\n",
    "    for pack in os.walk(dir):\n",
    "        for f in pack[2]:\n",
    "            counter += 1\n",
    "    return dir + \" : \" + str(counter) + \"files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1P1QjYhhaqE",
    "outputId": "26ed6971-cdd7-4152-b031-0eedb82c5a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images for training : X:\\Projects\\tomato\\train : 6097files\n",
      "total images for validation : X:\\Projects\\tomato\\val : 871files\n",
      "total images for validation : X:\\Projects\\tomato\\test : 1744files\n"
     ]
    }
   ],
   "source": [
    "print('total images for training :', count(train_path))\n",
    "print('total images for validation :', count(validation_path))\n",
    "print('total images for validation :', count(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2UOsr8CIh8W",
    "outputId": "5b213653-2c6a-4f0f-eb29-0a48875ed5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "folders = glob('X:\\\\Projects\\\\tomato\\\\train\\\\*')\n",
    "print(len(folders))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kWKNSZfiKAhS"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_generator = ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.1) # VGG16 preprocessing\n",
    "\n",
    "validation_generator = ImageDataGenerator(preprocessing_function=preprocess_input) \n",
    "\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvg_tLEaJw06",
    "outputId": "1b40c140-ed8e-4dec-dc01-744bce2bc4e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bacterialspot', 'earlyblight', 'healthy', 'lateblight', 'leafmold', 'mosaicvirus', 'septorialeafspot', 'spidermites', 'targetspot', 'yellowleafcurlvirus']\n",
      "Found 5488 images belonging to 10 classes.\n",
      "Found 609 images belonging to 10 classes.\n",
      "Found 1744 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "class_subset = sorted(os.listdir('X:\\\\Projects\\\\tomato\\\\train'))\n",
    "print(class_subset)\n",
    "traingen = train_generator.flow_from_directory(train_path,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=class_subset,\n",
    "                                               subset='training',\n",
    "                                               batch_size=BATCH_SIZE, \n",
    "                                               shuffle=True,\n",
    "                                               seed=5)\n",
    "\n",
    "validgen = train_generator.flow_from_directory(train_path,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='categorical',\n",
    "                                               classes=class_subset,\n",
    "                                               subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=4)\n",
    "\n",
    "testgen = test_generator.flow_from_directory(test_path,\n",
    "                                             target_size=(224, 224),\n",
    "                                             class_mode=None,\n",
    "                                             classes=class_subset,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7bqEPLfQ68Q"
   },
   "source": [
    "# **VGG16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NfwZt7lQtdt",
    "outputId": "d3e3054a-61dd-405e-ceae-c4858964e1c2"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model1 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "X5XDzROhQth6"
   },
   "outputs": [],
   "source": [
    "for layer in model1.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpfFgaqnDz1U",
    "outputId": "4d2bd4b8-fa3e-4830-b31c-0d8c86484fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "2S96C1OcQtmw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "batnorm = layers.BatchNormalization()\n",
    "dropout = layers.Dropout(0.20)\n",
    "prediction_layer = layers.Dense(10, activation='sigmoid')\n",
    "\n",
    "\n",
    "vgg16 = models.Sequential([\n",
    "    model1,\n",
    "    flatten_layer,\n",
    "    batnorm,\n",
    "    dropout,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQh6SGWSQtpI",
    "outputId": "37d164ac-7a4c-4a88-9d5d-f00628c01e0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 25088)             100352    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                250890    \n",
      "=================================================================\n",
      "Total params: 15,065,930\n",
      "Trainable params: 301,066\n",
      "Non-trainable params: 14,764,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fW1pFlgtQtwD",
    "outputId": "902d0ae3-21ff-43d0-b89b-15d2881cb924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 40s 456ms/step - loss: 0.6806 - accuracy: 0.7972 - val_loss: 0.4839 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.87847, saving model to X:\\Projects\\tomato\\vgg16.h5\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 39s 462ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.3953 - val_accuracy: 0.8924\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.87847 to 0.89236, saving model to X:\\Projects\\tomato\\vgg16.h5\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 41s 486ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 0.3782 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.89236 to 0.90972, saving model to X:\\Projects\\tomato\\vgg16.h5\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 42s 496ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.3487 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.90972 to 0.91667, saving model to X:\\Projects\\tomato\\vgg16.h5\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 42s 497ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.3577 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91667\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 43s 503ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.9132\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91667\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 43s 503ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91667\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 43s 508ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91667\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 43s 505ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4161 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.91667\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 43s 511ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.4168 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91667\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 44s 513ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.4155 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91667 to 0.92535, saving model to X:\\Projects\\tomato\\vgg16.h5\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 43s 511ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.4239 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.92535\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 43s 510ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.3893 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.92535\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 43s 511ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.4279 - val_accuracy: 0.9132\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.92535\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 43s 511ms/step - loss: 9.3880e-04 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.92535\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 43s 510ms/step - loss: 8.3235e-04 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.9132\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92535\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 43s 511ms/step - loss: 6.1347e-04 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92535\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 43s 511ms/step - loss: 5.5411e-04 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92535\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 44s 512ms/step - loss: 5.4344e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92535\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 43s 510ms/step - loss: 5.6748e-04 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92535\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 43s 510ms/step - loss: 5.0095e-04 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.92535\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 43s 511ms/step - loss: 4.6044e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92535\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 43s 508ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.5227 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92535\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 43s 510ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.5694 - val_accuracy: 0.9010\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.92535\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 43s 507ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.7892 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92535\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 44s 512ms/step - loss: 0.0534 - accuracy: 0.9854 - val_loss: 0.8412 - val_accuracy: 0.8906\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.92535\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 43s 508ms/step - loss: 0.0991 - accuracy: 0.9746 - val_loss: 0.9547 - val_accuracy: 0.8663\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.92535\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 43s 509ms/step - loss: 0.0971 - accuracy: 0.9786 - val_loss: 0.9722 - val_accuracy: 0.8958\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92535\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 43s 511ms/step - loss: 0.0521 - accuracy: 0.9871 - val_loss: 0.9929 - val_accuracy: 0.8924\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92535\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 43s 507ms/step - loss: 0.0569 - accuracy: 0.9851 - val_loss: 0.9080 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.92535\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 43s 507ms/step - loss: 0.0310 - accuracy: 0.9919 - val_loss: 0.9118 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.92535\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 43s 509ms/step - loss: 0.0246 - accuracy: 0.9935 - val_loss: 0.8403 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.92535\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 43s 508ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.9035 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.92535\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 43s 509ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 1.0801 - val_accuracy: 0.8993\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.92535\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 43s 507ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 1.0556 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.92535\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 43s 506ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.9296 - val_accuracy: 0.9132\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.92535\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 43s 506ms/step - loss: 0.0221 - accuracy: 0.9956 - val_loss: 1.0420 - val_accuracy: 0.9028\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.92535\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 45s 527ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 1.0830 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.92535\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 44s 523ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 1.1351 - val_accuracy: 0.9132\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.92535\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 45s 525ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.9872 - val_accuracy: 0.9080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.92535\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 45s 524ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 1.0836 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.92535\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 44s 521ms/step - loss: 0.0042 - accuracy: 0.9982 - val_loss: 1.1199 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.92535\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 44s 517ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.0794 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.92535\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 45s 527ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.9475 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.92535\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 45s 527ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.9556 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.92535\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 45s 526ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 1.1024 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.92535\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 45s 526ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 1.1052 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.92535\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 45s 526ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 1.1779 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.92535\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 45s 526ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.1000 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.92535\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 45s 527ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 1.2104 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.92535\n"
     ]
    }
   ],
   "source": [
    "optimizer=Adam(learning_rate=0.001)\n",
    "vgg16.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "optim_1 = Adam(learning_rate=0.001)\n",
    "#n_classes=3\n",
    "\n",
    "n_steps = traingen.samples // BATCH_SIZE\n",
    "n_val_steps = validgen.samples // BATCH_SIZE\n",
    "n_epochs = 50\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='X:\\\\Projects\\\\tomato\\\\vgg16.h5',\n",
    "                                  save_best_only=True,\n",
    "                                  monitor='val_accuracy',\n",
    "                                  mode='max',\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "\n",
    "vgg_history = vgg16.fit(traingen,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=n_epochs,\n",
    "                            validation_data=validgen,\n",
    "                            steps_per_epoch=n_steps,\n",
    "                            validation_steps=n_val_steps,\n",
    "                            callbacks=[tl_checkpoint_1], \n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "USB2Vx_RQt0P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Generate predictions\n",
    "vgg16.load_weights('X:\\\\Projects\\\\tomato\\\\vgg16.h5') # initialize the best trained weights\n",
    "\n",
    "true_classes = testgen.classes\n",
    "class_indices = traingen.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "vgg_preds = vgg16.predict(testgen)\n",
    "vgg_pred_classes = np.argmax(vgg_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdK5KqiWbwiq",
    "outputId": "55af6a63-b3de-4a10-d836-6e24df793735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 Model Accuracy without Fine-Tuning: 90.71%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vgg_acc = accuracy_score(true_classes, vgg_pred_classes)\n",
    "print(\"VGG16 Model Accuracy without Fine-Tuning: {:.2f}%\".format(vgg_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRj2ZJ_nb5WY",
    "outputId": "0ee26ff2-4644-457c-cdc1-dd6c4c9c0ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        78\n",
      "           1       0.86      0.82      0.84       200\n",
      "           2       0.98      0.96      0.97       200\n",
      "           3       0.89      0.87      0.88       200\n",
      "           4       0.95      0.93      0.94       191\n",
      "           5       0.91      0.96      0.94        75\n",
      "           6       0.87      0.84      0.86       200\n",
      "           7       0.92      0.94      0.93       200\n",
      "           8       0.88      0.91      0.89       200\n",
      "           9       0.95      0.99      0.97       200\n",
      "\n",
      "    accuracy                           0.91      1744\n",
      "   macro avg       0.90      0.91      0.90      1744\n",
      "weighted avg       0.91      0.91      0.91      1744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(true_classes,vgg_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukUvLfMsb5Y5",
    "outputId": "41aec502-0495-4565-be27-2d2600e4e36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 65   5   0   1   0   0   2   1   0   4]\n",
      " [  5 165   1  13   3   0   6   1   3   3]\n",
      " [  0   1 193   0   0   0   2   0   4   0]\n",
      " [  0  13   1 174   4   0   4   1   2   1]\n",
      " [  0   1   0   4 177   2   5   2   0   0]\n",
      " [  0   0   0   0   0  72   3   0   0   0]\n",
      " [  6   4   1   4   3   2 169   2   8   1]\n",
      " [  0   0   0   0   0   3   0 187   9   1]\n",
      " [  2   2   1   0   0   0   4   8 182   1]\n",
      " [  0   1   0   0   0   0   0   1   0 198]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(true_classes,vgg_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLHlCxgZkx7f"
   },
   "source": [
    "# **ResNet152**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdvBEolGWaBV",
    "outputId": "1b924b1e-2d91-4d84-9e45-7397bd2a8404"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import keras\n",
    "model6 = tf.keras.applications.ResNet152(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "for layer in model6.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3zw_HYpk7GT",
    "outputId": "0c7be66e-ffcc-43aa-f9f6-ad70ec2e0973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet152\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_relu (Activation (None, 28, 28, 128)  0           conv3_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_add (Add)          (None, 28, 28, 512)  0           conv3_block4_out[0][0]           \n",
      "                                                                 conv3_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_out (Activation)   (None, 28, 28, 512)  0           conv3_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_relu (Activation (None, 28, 28, 128)  0           conv3_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_add (Add)          (None, 28, 28, 512)  0           conv3_block5_out[0][0]           \n",
      "                                                                 conv3_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_out (Activation)   (None, 28, 28, 512)  0           conv3_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_relu (Activation (None, 28, 28, 128)  0           conv3_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_add (Add)          (None, 28, 28, 512)  0           conv3_block6_out[0][0]           \n",
      "                                                                 conv3_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_out (Activation)   (None, 28, 28, 512)  0           conv3_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_relu (Activation (None, 28, 28, 128)  0           conv3_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_add (Add)          (None, 28, 28, 512)  0           conv3_block7_out[0][0]           \n",
      "                                                                 conv3_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_out (Activation)   (None, 28, 28, 512)  0           conv3_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 14, 14, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 14, 14, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 14, 14, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 14, 14, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 14, 14, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 14, 14, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 14, 14, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 14, 14, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 14, 14, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 14, 14, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 14, 14, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 14, 14, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 14, 14, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 14, 14, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 14, 14, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 14, 14, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 14, 14, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 14, 14, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 14, 14, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 14, 14, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 14, 14, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 14, 14, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 14, 14, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 14, 14, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 14, 14, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 14, 14, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 14, 14, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 14, 14, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 14, 14, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 14, 14, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 14, 14, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 14, 14, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 14, 14, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 14, 14, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 14, 14, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 14, 14, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 14, 14, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block24_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block24_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_add (Add)         (None, 14, 14, 1024) 0           conv4_block23_out[0][0]          \n",
      "                                                                 conv4_block24_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_out (Activation)  (None, 14, 14, 1024) 0           conv4_block24_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block24_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block25_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block25_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_add (Add)         (None, 14, 14, 1024) 0           conv4_block24_out[0][0]          \n",
      "                                                                 conv4_block25_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_out (Activation)  (None, 14, 14, 1024) 0           conv4_block25_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block25_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block26_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block26_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_add (Add)         (None, 14, 14, 1024) 0           conv4_block25_out[0][0]          \n",
      "                                                                 conv4_block26_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_out (Activation)  (None, 14, 14, 1024) 0           conv4_block26_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block26_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block27_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block27_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_add (Add)         (None, 14, 14, 1024) 0           conv4_block26_out[0][0]          \n",
      "                                                                 conv4_block27_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_out (Activation)  (None, 14, 14, 1024) 0           conv4_block27_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block27_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block28_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block28_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_add (Add)         (None, 14, 14, 1024) 0           conv4_block27_out[0][0]          \n",
      "                                                                 conv4_block28_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_out (Activation)  (None, 14, 14, 1024) 0           conv4_block28_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block28_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block29_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block29_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_add (Add)         (None, 14, 14, 1024) 0           conv4_block28_out[0][0]          \n",
      "                                                                 conv4_block29_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_out (Activation)  (None, 14, 14, 1024) 0           conv4_block29_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block29_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block30_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block30_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_add (Add)         (None, 14, 14, 1024) 0           conv4_block29_out[0][0]          \n",
      "                                                                 conv4_block30_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_out (Activation)  (None, 14, 14, 1024) 0           conv4_block30_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block30_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block31_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block31_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_add (Add)         (None, 14, 14, 1024) 0           conv4_block30_out[0][0]          \n",
      "                                                                 conv4_block31_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_out (Activation)  (None, 14, 14, 1024) 0           conv4_block31_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block31_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block32_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block32_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_add (Add)         (None, 14, 14, 1024) 0           conv4_block31_out[0][0]          \n",
      "                                                                 conv4_block32_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_out (Activation)  (None, 14, 14, 1024) 0           conv4_block32_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block32_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block33_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block33_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_add (Add)         (None, 14, 14, 1024) 0           conv4_block32_out[0][0]          \n",
      "                                                                 conv4_block33_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_out (Activation)  (None, 14, 14, 1024) 0           conv4_block33_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block33_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block34_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block34_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_add (Add)         (None, 14, 14, 1024) 0           conv4_block33_out[0][0]          \n",
      "                                                                 conv4_block34_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_out (Activation)  (None, 14, 14, 1024) 0           conv4_block34_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block34_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block35_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block35_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_add (Add)         (None, 14, 14, 1024) 0           conv4_block34_out[0][0]          \n",
      "                                                                 conv4_block35_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_out (Activation)  (None, 14, 14, 1024) 0           conv4_block35_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block35_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 14, 14, 256)  590080      conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_bn (BatchNormal (None, 14, 14, 256)  1024        conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block36_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      conv4_block36_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_3_bn (BatchNormal (None, 14, 14, 1024) 4096        conv4_block36_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_add (Add)         (None, 14, 14, 1024) 0           conv4_block35_out[0][0]          \n",
      "                                                                 conv4_block36_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_out (Activation)  (None, 14, 14, 1024) 0           conv4_block36_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block36_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block36_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 58,370,944\n",
      "Trainable params: 0\n",
      "Non-trainable params: 58,370,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "gE7kYfFkk_pA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "batnorm = layers.BatchNormalization()\n",
    "dropout = layers.Dropout(0.20)\n",
    "prediction_layer = layers.Dense(10, activation='sigmoid')\n",
    "\n",
    "resnet152 = models.Sequential([\n",
    "    model6,\n",
    "    flatten_layer,\n",
    "    batnorm,\n",
    "    dropout,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV4YQqrzlEit",
    "outputId": "79542b43-8044-423a-8439-fd36149c6f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet152 (Functional)       (None, 7, 7, 2048)        58370944  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100352)            401408    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1003530   \n",
      "=================================================================\n",
      "Total params: 59,775,882\n",
      "Trainable params: 1,204,234\n",
      "Non-trainable params: 58,571,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet152.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlAtN3dwlGVD",
    "outputId": "530c72f4-28c6-4eec-9764-75014f6027a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 86s 884ms/step - loss: 1.1329 - accuracy: 0.8282 - val_loss: 0.6960 - val_accuracy: 0.9028\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.90278, saving model to X:\\Projects\\tomato\\resnet152.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhala\\anaconda3\\envs\\NNDL\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "85/85 [==============================] - 73s 859ms/step - loss: 0.2257 - accuracy: 0.9622 - val_loss: 0.6791 - val_accuracy: 0.8976\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.90278\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 75s 887ms/step - loss: 0.0977 - accuracy: 0.9836 - val_loss: 0.7878 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.90278 to 0.92361, saving model to X:\\Projects\\tomato\\resnet152.h5\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 74s 870ms/step - loss: 0.0681 - accuracy: 0.9880 - val_loss: 0.9097 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.92361 to 0.92882, saving model to X:\\Projects\\tomato\\resnet152.h5\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 74s 874ms/step - loss: 0.0388 - accuracy: 0.9924 - val_loss: 0.8731 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.92882\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 76s 890ms/step - loss: 0.0449 - accuracy: 0.9924 - val_loss: 0.9216 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.92882\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 78s 920ms/step - loss: 0.0238 - accuracy: 0.9954 - val_loss: 0.9879 - val_accuracy: 0.9323\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.92882 to 0.93229, saving model to X:\\Projects\\tomato\\resnet152.h5\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 77s 909ms/step - loss: 0.0214 - accuracy: 0.9950 - val_loss: 0.8894 - val_accuracy: 0.9358\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.93229 to 0.93576, saving model to X:\\Projects\\tomato\\resnet152.h5\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 77s 905ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 1.0645 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.93576\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 79s 925ms/step - loss: 0.0619 - accuracy: 0.9888 - val_loss: 1.0112 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.93576\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 78s 923ms/step - loss: 0.0475 - accuracy: 0.9921 - val_loss: 1.3566 - val_accuracy: 0.9132\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.93576\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 79s 928ms/step - loss: 0.0326 - accuracy: 0.9939 - val_loss: 1.2145 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.93576\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 79s 929ms/step - loss: 0.0523 - accuracy: 0.9930 - val_loss: 1.4038 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.93576\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 79s 931ms/step - loss: 0.0803 - accuracy: 0.9900 - val_loss: 1.4103 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.93576\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 79s 932ms/step - loss: 0.0421 - accuracy: 0.9937 - val_loss: 1.3402 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.93576\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 79s 925ms/step - loss: 0.0634 - accuracy: 0.9932 - val_loss: 1.5328 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.93576\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 77s 907ms/step - loss: 0.0763 - accuracy: 0.9934 - val_loss: 1.1573 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.93576 to 0.93924, saving model to X:\\Projects\\tomato\\resnet152.h5\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 76s 897ms/step - loss: 0.0527 - accuracy: 0.9939 - val_loss: 1.6396 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.93924\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 78s 916ms/step - loss: 0.0578 - accuracy: 0.9937 - val_loss: 1.4593 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.93924\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 76s 897ms/step - loss: 0.0620 - accuracy: 0.9939 - val_loss: 1.3016 - val_accuracy: 0.9323\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.93924\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 77s 902ms/step - loss: 0.0404 - accuracy: 0.9952 - val_loss: 1.4837 - val_accuracy: 0.9323\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.93924\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 78s 917ms/step - loss: 0.0486 - accuracy: 0.9937 - val_loss: 1.4170 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.93924 to 0.94444, saving model to X:\\Projects\\tomato\\resnet152.h5\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 77s 909ms/step - loss: 0.0375 - accuracy: 0.9950 - val_loss: 1.0471 - val_accuracy: 0.9358\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.94444\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 79s 927ms/step - loss: 0.0290 - accuracy: 0.9958 - val_loss: 1.5409 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.94444\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 79s 925ms/step - loss: 0.1062 - accuracy: 0.9923 - val_loss: 1.8858 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.94444\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 77s 911ms/step - loss: 0.0595 - accuracy: 0.9939 - val_loss: 1.8032 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.94444\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 76s 898ms/step - loss: 0.0418 - accuracy: 0.9954 - val_loss: 1.3831 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.94444\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 78s 919ms/step - loss: 0.0275 - accuracy: 0.9974 - val_loss: 1.5443 - val_accuracy: 0.9427\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.94444\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 79s 924ms/step - loss: 0.0510 - accuracy: 0.9959 - val_loss: 1.5361 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.94444\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 76s 899ms/step - loss: 0.0429 - accuracy: 0.9959 - val_loss: 1.2892 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.94444\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 76s 899ms/step - loss: 0.0503 - accuracy: 0.9948 - val_loss: 1.4694 - val_accuracy: 0.9340\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.94444\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 76s 898ms/step - loss: 0.0252 - accuracy: 0.9972 - val_loss: 1.2286 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.94444\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 77s 912ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 1.4297 - val_accuracy: 0.9462\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.94444 to 0.94618, saving model to X:\\Projects\\tomato\\resnet152.h5\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 78s 914ms/step - loss: 0.0165 - accuracy: 0.9980 - val_loss: 1.5862 - val_accuracy: 0.9462\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.94618\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 79s 924ms/step - loss: 0.0266 - accuracy: 0.9980 - val_loss: 1.4787 - val_accuracy: 0.9410\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.94618\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 79s 930ms/step - loss: 0.0269 - accuracy: 0.9976 - val_loss: 1.4580 - val_accuracy: 0.9479\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.94618 to 0.94792, saving model to X:\\Projects\\tomato\\resnet152.h5\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 78s 911ms/step - loss: 0.0236 - accuracy: 0.9980 - val_loss: 1.6701 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.94792\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 79s 928ms/step - loss: 0.0296 - accuracy: 0.9967 - val_loss: 1.5493 - val_accuracy: 0.9497\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.94792 to 0.94965, saving model to X:\\Projects\\tomato\\resnet152.h5\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 77s 904ms/step - loss: 0.0491 - accuracy: 0.9963 - val_loss: 1.7184 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.94965\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 78s 913ms/step - loss: 0.0444 - accuracy: 0.9945 - val_loss: 2.2185 - val_accuracy: 0.9410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.94965\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 78s 912ms/step - loss: 0.0350 - accuracy: 0.9971 - val_loss: 1.9634 - val_accuracy: 0.9410\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.94965\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 77s 910ms/step - loss: 0.0241 - accuracy: 0.9967 - val_loss: 1.9349 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.94965\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 77s 906ms/step - loss: 0.0673 - accuracy: 0.9958 - val_loss: 2.3579 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.94965\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 77s 905ms/step - loss: 0.0338 - accuracy: 0.9969 - val_loss: 2.1273 - val_accuracy: 0.9271\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.94965\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 76s 899ms/step - loss: 0.0533 - accuracy: 0.9954 - val_loss: 2.0395 - val_accuracy: 0.9358\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.94965\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 77s 901ms/step - loss: 0.0692 - accuracy: 0.9969 - val_loss: 2.5214 - val_accuracy: 0.9340\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.94965\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 76s 898ms/step - loss: 0.0647 - accuracy: 0.9961 - val_loss: 2.0225 - val_accuracy: 0.9410\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.94965\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 77s 900ms/step - loss: 0.0401 - accuracy: 0.9959 - val_loss: 1.7309 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.94965\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 77s 901ms/step - loss: 0.0255 - accuracy: 0.9976 - val_loss: 1.9365 - val_accuracy: 0.9358\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.94965\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 76s 894ms/step - loss: 0.0247 - accuracy: 0.9980 - val_loss: 1.8493 - val_accuracy: 0.9410\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.94965\n"
     ]
    }
   ],
   "source": [
    "optimizer=Adam(learning_rate=0.001)\n",
    "resnet152.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "optim_1 = Adam(learning_rate=0.001)\n",
    "#n_classes=3\n",
    "\n",
    "n_steps = traingen.samples // BATCH_SIZE\n",
    "n_val_steps = validgen.samples // BATCH_SIZE\n",
    "n_epochs = 50\n",
    "\n",
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='X:\\\\Projects\\\\tomato\\\\resnet152.h5',\n",
    "                                  save_best_only=True,\n",
    "                                  monitor='val_accuracy',\n",
    "                                  mode='max',\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')\n",
    "\n",
    "\n",
    "vgg_history = resnet152.fit(traingen,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=n_epochs,\n",
    "                            validation_data=validgen,\n",
    "                            steps_per_epoch=n_steps,\n",
    "                            validation_steps=n_val_steps,\n",
    "                            callbacks=[tl_checkpoint_1], \n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "1285-HBYVspX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Generate predictions\n",
    "resnet152= tf.keras.models.load_model('X:\\\\Projects\\\\tomato\\\\resnet152.h5') # initialize the best trained weights\n",
    "\n",
    "true_classes = testgen.classes\n",
    "class_indices = traingen.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "resnet152_preds = resnet152.predict(testgen)\n",
    "resnet152_pred_classes = np.argmax(resnet152_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIVwl1tDVvei",
    "outputId": "e7d0ac4f-bebe-43fb-a370-c29327cec209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet152 Model Accuracy without Fine-Tuning: 39.39%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "resnet152_acc = accuracy_score(true_classes, resnet152_pred_classes)\n",
    "print(\"ResNet152 Model Accuracy without Fine-Tuning: {:.2f}%\".format(resnet152_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JU3cJPCVyoJ",
    "outputId": "15a28db3-2834-4d0f-dd78-bafc6e6d7e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      1.00      0.38        78\n",
      "           1       0.30      0.67      0.41       200\n",
      "           2       0.54      0.84      0.66       200\n",
      "           3       0.37      0.36      0.37       200\n",
      "           4       0.40      0.46      0.43       191\n",
      "           5       0.41      0.33      0.37        75\n",
      "           6       0.42      0.14      0.20       200\n",
      "           7       0.75      0.28      0.40       200\n",
      "           8       1.00      0.13      0.23       200\n",
      "           9       1.00      0.07      0.12       200\n",
      "\n",
      "    accuracy                           0.39      1744\n",
      "   macro avg       0.54      0.43      0.36      1744\n",
      "weighted avg       0.57      0.39      0.35      1744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(true_classes,resnet152_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQu2EZEDlbVW",
    "outputId": "4456f124-7d56-46ea-afa5-36101d4871e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 66, 133,   0,   1,   0,   0,   0,   0,   0,   0],\n",
       "       [ 16,  15, 169,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 44,  66,  17,  73,   0,   0,   0,   0,   0,   0],\n",
       "       [  6,  37,  13,  47,  88,   0,   0,   0,   0,   0],\n",
       "       [  0,  10,   7,   2,  31,  25,   0,   0,   0,   0],\n",
       "       [ 68,  44,  11,  22,  22,   6,  27,   0,   0,   0],\n",
       "       [  5,  26,  31,  33,  28,  13,   9,  55,   0,   0],\n",
       "       [ 28,  40,  48,   7,  11,   8,  18,  14,  26,   0],\n",
       "       [ 20,  75,  18,  10,  41,   9,  10,   4,   0,  13]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true_classes,resnet152_pred_classes)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BCD_smallData_part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
